import random
import math
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

class Trading_Agent(object):
    valid_actions = ['buy', 'sell', 'hold']

    def __init__(self, learning, epsilon, alpha, values, states, Q, i, quantity, start_date):

        # Set parameters of the learning agent
        self.learning = learning # Whether the agent is expected to learn
        self.Q = Q          # Create a Q-table which will be a dictionary of tuples
        self.epsilon = epsilon   # Random exploration factor
        self.alpha = alpha       # Learning factor
        self.values = values
        self.states = states
        self.start_date = start_date
        self.asset_value=[(self.start_date, 50, 50*self.values[0][1],0,50*self.values[0][1], 50*self.values[0][1]),]
        self.i=i
        self.quantity = quantity
        self.cumulative_returns = [0,]
        self.nifty_cumulative_returns = [0,]
        self.risk_free_returns = [0,]

    def build_state(self):
        """ The build_state function is called when the agent requests data about the state"""

        # Set 'state' as a tuple of relevant data for the agent 
        state = states[self.i]
        return state


    def get_maxQ(self, state):
        """ The get_maxQ function is called when the agent is asked to find the
            maximum Q-value of all actions based on the 'state'. """

      
        # Calculate the maximum Q-value of all actions for a given state

        maxQ = max(self.Q[state].values())
        max_actions = []
        for key, value in self.Q[state].iteritems():
            if maxQ == value:
                max_actions.append(key)
        return maxQ, max_actions 


    def createQ(self, state):
        """ The createQ function is called when a state is generated by the agent. """


        # When learning, check if the 'state' is not in the Q-table
        # If it is not, create a new dictionary for that state
        #   Then, for each action available, set the initial Q-value to 0.0
        if self.learning == True:
            if not state in self.Q:
                self.Q[state]=self.Q.get(state,{'buy':0.0, 'sell':0.0, 'hold':0.0})

        return


    def choose_action(self, state):
        """ The choose_action function is called when the agent is asked to choose
            which action to take, based on the 'state'. """

        action = None
        # When learning, choose a random action with 'epsilon' probability
        # Otherwise, choose an action with the highest Q-value for the current state
        if self.learning == False:
            if not state in self.Q:
                action = random.choice(self.valid_actions)
            else:
                maxQ, max_actions = self.get_maxQ(state)
                action = random.choice(max_actions)
        if self.learning == True:
            if random.random() < self.epsilon:
                action = random.choice(self.valid_actions)
            else:
                    maxQ, max_actions = self.get_maxQ(state)
                    action=random.choice(max_actions)
        return action


    def learn(self, state, action, reward):
        """ The learn function is called after the agent completes an action and
            receives a reward. """

        if self.learning == True:
            self.Q[state][action] = reward * self.alpha + self.Q[state][action]*(1-self.alpha)
        return


    def update(self):
        """ The update function is called for each closing price. This function will build the agent
            state, choose an action, receive a reward, and learn if enabled. """
        if self.learning == True:
            datarange = 247
        else: datarange = 123
        for self.i in range(datarange):
            state = self.build_state()          # Get current state
            self.createQ(state)                 # Create 'state' in Q-table
            action = self.choose_action(state)  # Choose an action
            reward = self.asset(action) # Receive a reward
            self.learn(state, action, reward) # Q-learn
            if self.learning == False:
                self.cumulative_returns.append(self.cumulative_returns[self.i]+(self.asset_value[self.i+1][4]/self.asset_value[self.i][4]-1))
                self.nifty_cumulative_returns.append(self.nifty_cumulative_returns[self.i] + self.values[self.i+1][1]/self.values[self.i][1]-1)
                self.risk_free_returns.append(self.risk_free_returns[self.i]+0.00027823)
                
        if self.learning == False:
                print(self.asset_value)
                Date, Nifty_Units, Nifty_Asset, Risk_Free_Asset, Total_Asset, Total_Nifty = zip(*self.asset_value)
                plt.xlabel("Date") 
                plt.ylabel("Asset Value in INR")
                plt.plot(Date, Total_Asset, color='green')
                plt.plot(Date, Total_Nifty, color='blue')
                plt.show()
                print("Q learner returns = "+str(round(self.cumulative_returns[-1]*100,3))+"%")
                print("Nifty returns = "+str(round(self.nifty_cumulative_returns[-1]*100,3))+"%")
                q_learner =np.array(self.cumulative_returns)
                nifty=np.array(self.nifty_cumulative_returns)
                print("Q learner std deviation = "+str(round(np.std(q_learner[1:]),3)))
                print ("Nifty std deviation = "+str(round(np.std(nifty[1:]),3)))
                plt.xlabel("Date") 
                plt.ylabel("Returns")
                plt.plot(Date[1:], self.cumulative_returns[1:], color='green')
                plt.plot(Date[1:], self.nifty_cumulative_returns[1:], color='blue')
                plt.plot(Date[1:], self.risk_free_returns[1:], color='purple')
                plt.show()
                
                #plt.xlabel("Date")
                #plt.ylabel("Rewards")
                #plt.plot(Date, self.cumulative_rewards, color='green')
                #plt.plot(Date, self.nifty_cumulative_rewards, color='blue')
                #plt.show()
        return
        
    def asset(self, action):
        if action == 'buy':
            new_asset_value = (self.values[self.i+1][0], self.asset_value[self.i][1]+self.quantity, (self.asset_value[self.i][1]+self.quantity)*self.values[self.i+1][1], (self.asset_value[self.i][3]-self.quantity*self.values[self.i+1][1])*1.00027823, (self.asset_value[self.i][1]+self.quantity)*self.values[self.i+1][1]+(self.asset_value[self.i][3]-self.quantity*self.values[self.i+1][1])*1.00027823, 50*self.values[self.i+1][1])
        elif action == 'sell':
            new_asset_value = (self.values[self.i+1][0], self.asset_value[self.i][1]-self.quantity, (self.asset_value[self.i][1]-self.quantity)*self.values[self.i+1][1], (self.asset_value[self.i][3]+self.quantity*self.values[self.i+1][1])*1.00027823, (self.asset_value[self.i][1]-self.quantity)*self.values[self.i+1][1]+(self.asset_value[self.i][3]+self.quantity*self.values[self.i+1][1])*1.00027823, 50*self.values[self.i+1][1])
        elif action == 'hold':
            new_asset_value = (self.values[self.i+1][0], self.asset_value[self.i][1],(self.asset_value[self.i][1])*self.values[self.i+1][1], (self.asset_value[self.i][3])*1.00027823, (self.asset_value[self.i][1])*self.values[self.i+1][1]+(self.asset_value[self.i][3])*1.00027823, 50*self.values[self.i+1][1])
        self.asset_value.append(new_asset_value)
        closing = self.asset_value[self.i+1][2]+self.asset_value[self.i+1][3]
        next_day_closing = self.asset_value[self.i][2]+self.asset_value[self.i][3]
        sharpe_ratio = (((closing/next_day_closing)-1)-0.00027823)/(self.values[self.i][2]/100)
        return sharpe_ratio
        


values_df=pd.read_excel("values.xlsx")
states_df=pd.read_excel("states.xlsx")
values=[]
states=[]

for index, row in values_df.iterrows():
    data=(row["Date"],row["Nifty"],row["VIX"])
    values.append(data)
for index, row in states_df.iterrows():
    data=(row["5 day MA"], row["10 day MA"],row["20 day MA"],row["VIX"],row["RSI"],row["MACD"])
    states.append(data)
Q = dict()
epsilon = 1
alpha = 0.75
quantity = 5
for trial in range(1,1000):
    epsilon = 0.995 ** trial
    # epsilon = 1.0/(trial**2)
    # epsilon = 1.0/(trial**2 + alpha*trial)
    # epsilon = 1.0/(trial**2 - alpha*trial)
    # epsilon = math.fabs(math.cos(alpha*trial))
    # epsilon = math.fabs(math.cos(alpha*trial))/(trial**2)
    agent=Trading_Agent(True, epsilon, alpha, values, states, Q, 0, quantity, values[0][0])
    agent.update()
test_values_df=pd.read_excel("test_values.xlsx")
test_states_df=pd.read_excel("test_states.xlsx")
test_values=[]
test_states=[]
for index, row in test_values_df.iterrows():
    data=(row["Date"],row["Nifty"],row["VIX"])
    test_values.append(data)
for index, row in test_states_df.iterrows():
    data=(row["5 day MA"],row["10 day MA"],row["20 day MA"],row["VIX"],row["RSI"],row["MACD"])
    test_states.append(data)
agent=Trading_Agent(False, 0, 0, test_values, test_states, Q, 0, quantity, test_values[0][0])
agent.update()